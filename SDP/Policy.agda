------------------------------------------------------------------------
-- Policies and policy sequences
------------------------------------------------------------------------

open import SDP.SDP
open import Monad

module SDP.Policy
  {M} {isMonad : Monad M}
  (sdp : SDP isMonad)
  where

open SDP sdp

open import Data.Nat.Base
open import Agda.Builtin.Equality

private variable
  t n : ‚Ñï

-- Policies

Policy : ‚Ñï ‚Üí Set
Policy t = (x : State t) ‚Üí Ctrl x

-- Policy sequences

data PolicySeq (t : ‚Ñï) : (n : ‚Ñï) ‚Üí Set where
  [] : PolicySeq t 0
  _‚à∑_ : (p : Policy t) ‚Üí (ps : PolicySeq (suc t) n) ‚Üí PolicySeq t (suc n)

infixr 5 _‚à∑_

-- Computing the value of a policy sequence

val : PolicySeq t n ‚Üí State t ‚Üí Val
val [] x = ùüò
val (p ‚à∑ ps) x =
  let y = p x
      mx‚Ä≤ = next x y
  in  measure (fmap (reward x y ‚äï‚Çó val ps) mx‚Ä≤)

-- Note that Bellman's equality holds definitionally with this definition of val

BellmanEq : (p : Policy t) (ps : PolicySeq (suc t) n) (x : State t)
          ‚Üí val (p ‚à∑ ps) x ‚â° measure (fmap (reward x (p x) ‚äï‚Çó val ps) (next x (p x)))
BellmanEq p ps x = refl

-- Optimal policy sequences

OptPolicySeq : PolicySeq t n ‚Üí Set
OptPolicySeq {t} {n} ps = (ps‚Ä≤ : PolicySeq t n) ‚Üí val ps‚Ä≤ ‚â§‚Çó val ps

-- Optimal extensions

OptExt : PolicySeq (suc t) n ‚Üí Policy t ‚Üí Set
OptExt ps p = ‚àÄ p‚Ä≤ ‚Üí val (p‚Ä≤ ‚à∑ ps) ‚â§‚Çó val (p ‚à∑ ps)

-- The type of functions that compute optimal extensions

record optExtFun : Set where
  field
    optExt : PolicySeq (suc t) n ‚Üí Policy t
    optExtSpec : (ps : PolicySeq (suc t) n) ‚Üí OptExt ps (optExt ps)

-- Bellman's optimality principle

Bellman : (p : Policy t) (ps : PolicySeq (suc t) n)
        ‚Üí OptExt ps p ‚Üí OptPolicySeq ps
        ‚Üí OptPolicySeq (p ‚à∑ ps)
Bellman p ps op ops (p‚Ä≤ ‚à∑ ps‚Ä≤) x = begin
  val (p‚Ä≤ ‚à∑ ps‚Ä≤) x ‚â°‚ü®‚ü©
  measure (fmap (reward x (p‚Ä≤ x) ‚äï‚Çó val ps‚Ä≤) (next x (p‚Ä≤ x)))
    ‚â≤‚ü® measure-mon (Œª x‚Ä≤ ‚Üí ‚äï-mon ‚â§-refl (ops ps‚Ä≤ x‚Ä≤)) (next x (p‚Ä≤ x)) ‚ü©
  measure (fmap (reward x (p‚Ä≤ x) ‚äï‚Çó val ps) (next x (p‚Ä≤ x)))
    ‚â°‚ü®‚ü©
  val (p‚Ä≤ ‚à∑ ps) x
    ‚â≤‚ü® op p‚Ä≤ x ‚ü©
  val (p ‚à∑ ps) x ‚àé
  where
  open ‚â§-Reasoning
